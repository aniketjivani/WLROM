{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "378075df",
   "metadata": {},
   "source": [
    "**Feb 20, 2024**: Only change is use of Conv PNODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06fdd93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "\n",
    "# %%\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "\n",
    "# %%\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "352fea84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'niters': 50,\n",
       " 'lr': 0.01,\n",
       " 'batch_size': 4,\n",
       " 'batch_time': 5,\n",
       " 'nsims_per_batch': 1,\n",
       " 'nepochs': 300,\n",
       " 'save': 'experiments/',\n",
       " 'load': None,\n",
       " 'random_seed': 1123,\n",
       " 'pnode': True,\n",
       " 'node_layers': 3,\n",
       " 'units': 90,\n",
       " 'nParamsToUse': 9,\n",
       " 'ds': 1}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# SPECIFY ARGS\n",
    "# Generative model for noisy data based on ODE\n",
    "parser = argparse.ArgumentParser('PNODE')\n",
    "\n",
    "# parser.add_argument('-n',  type=int, default=1, help=\"Size of the dataset\")\n",
    "# parser.add_argument('-n',  type=int, default=100, help=\"Size of the dataset\")\n",
    "\n",
    "parser.add_argument('--niters', type=int, \n",
    "                    default=50)\n",
    "parser.add_argument('--lr',  type=float, default=1e-2, help=\"Starting learning rate.\")\n",
    "parser.add_argument('-bs', '--batch-size', type=int, default=4)\n",
    "parser.add_argument('-bt', '--batch-time', type=int, default=5)\n",
    "parser.add_argument('-nspb', '--nsims_per_batch', type=int, default=1)\n",
    "parser.add_argument('-epch', '--nepochs', type=int, default=300)\n",
    "\n",
    "\n",
    "parser.add_argument('--save', type=str, default='experiments/', \n",
    "                    help=\"Path for save checkpoints\")\n",
    "parser.add_argument('--load', type=str, \n",
    "                    default=None, \n",
    "#                     default=86364,\n",
    "                    help=\"ID of the experiment to load for evaluation. If None, run a new experiment.\")\n",
    "parser.add_argument('-r', '--random-seed', type=int, default=1123, help=\"Random_seed\")\n",
    "\n",
    "\n",
    "parser.add_argument('--pnode', \n",
    "                    action='store_false', \n",
    "                    help=\"RUN parameterized neural ode\")\n",
    "parser.add_argument('--node-layers', \n",
    "                    type=int, \n",
    "                    default=3, \n",
    "                    help=\"number of layers in NODE\")\n",
    "\n",
    "parser.add_argument('-u', '--units', \n",
    "                    type=int, \n",
    "                    default=90, \n",
    "                    help=\"Number of units per layer in ODE func\")\n",
    "\n",
    "parser.add_argument('--nParamsToUse',\n",
    "                    type=int,\n",
    "                    default=9,\n",
    "                    help=\"Number of CME params to use\")\n",
    "\n",
    "# parser.add_argument('--normalize', type=bool, default=True)\n",
    "\n",
    "parser.add_argument('-ds',\n",
    "                    type=int,\n",
    "                    default=1,\n",
    "                    help=\"Coarsening factor for position angles\")\n",
    "\n",
    "# args = parser.parse_args(args=())\n",
    "args = parser.parse_args(args=())\n",
    "\n",
    "# %%\n",
    "vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e0255be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "import scipy.sparse as sparse\n",
    "import matplotlib.pyplot as plt\n",
    "from random import SystemRandom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0a5ead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6d079d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"axes.spines\", right=True, top=True)\n",
    "plt.rc(\"figure\", dpi=300, \n",
    "       figsize=(9, 3)\n",
    "      )\n",
    "plt.rc(\"font\", family=\"serif\")\n",
    "plt.rc(\"legend\", edgecolor=\"none\", frameon=True)\n",
    "plt.style.use(\"dark_background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acb3a22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2900e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjoint=True\n",
    "if adjoint:\n",
    "    from torchdiffeq import odeint_adjoint as odeint\n",
    "else:\n",
    "    from torchdiffeq import odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b75ccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import edge_utils as edut\n",
    "import node_1d_utils as nut\n",
    "\n",
    "# %%\n",
    "import logging\n",
    "\n",
    "# stealing this from: \n",
    "# https://github.com/rtqichen/torchdiffeq/blob/master/examples/odenet_mnist.py#L250C1-L274C18\n",
    "def get_logger(logpath, package_files=[], displaying=True, saving=True, debug=False):\n",
    "    logger = logging.getLogger()\n",
    "    if debug:\n",
    "        level = logging.DEBUG\n",
    "    else:\n",
    "        level = logging.INFO\n",
    "    logger.setLevel(level)\n",
    "    if saving:\n",
    "        info_file_handler = logging.FileHandler(logpath, mode=\"a\")\n",
    "        info_file_handler.setLevel(level)\n",
    "        logger.addHandler(info_file_handler)\n",
    "    if displaying:\n",
    "        console_handler = logging.StreamHandler()\n",
    "        console_handler.setLevel(level)\n",
    "        logger.addHandler(console_handler)\n",
    "        #     logger.info(filepath)\n",
    "\n",
    "        #     with open(filepath, \"r\") as f:\n",
    "        #         logger.info(f.read())\n",
    "\n",
    "        #     for f in package_files:\n",
    "        #         logger.info(f)\n",
    "        #         with open(f, \"r\") as package_f:\n",
    "        #             logger.info(package_f.read())\n",
    "\n",
    "    return logger\n",
    "\n",
    "\n",
    "# %%\n",
    "edut.makedirs(os.path.join(os.getcwd(), \"logs\"))\n",
    "logdir = os.path.join(os.getcwd(), \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2467b970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of angles for CR2161: -31.279843444227026 81.44031311154595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-31.        , -30.28930818, -29.57861635, -28.86792453,\n",
       "       -28.1572327 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_s_2161 = np.linspace(0, 360, 512)[160] + 1.2 * 180 - 360\n",
    "theta_e_2161 = np.linspace(0, 360, 512)[320] + 1.2 * 180 - 360\n",
    "print(\"Range of angles for CR2161: {} {}\".format(theta_s_2161, theta_e_2161))\n",
    "\n",
    "# %%\n",
    "ed_2161, sd_2161 = edut.load_edge_data_blobfree(2161)\n",
    "# crude downsample for now\n",
    "ed_2161 = ed_2161[:, ::args.ds, :]\n",
    "\n",
    "# %%\n",
    "nTimes, nTheta_2161, nSims_2161 = ed_2161.shape\n",
    "nTimes, nTheta_2161, nSims_2161\n",
    "\n",
    "# %%\n",
    "theta_grid = np.linspace(np.ceil(theta_s_2161), np.ceil(theta_e_2161), nTheta_2161 * args.ds)[::args.ds]\n",
    "theta_grid[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6ea0d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d48118d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 160, 278)\n"
     ]
    }
   ],
   "source": [
    "def getRValuesAllSims(edge_data_matrix, sample_freq=2):\n",
    "    \"\"\"\n",
    "    Return r values for all sims at once so we don't lose time in training processing r values repeatedly\n",
    "    \"\"\"\n",
    "    r_data_matrix = np.zeros(edge_data_matrix.shape)\n",
    "    nsims = edge_data_matrix.shape[2]\n",
    "    for i in range(nsims):\n",
    "        r_vals, theta_vals = edut.getRValues(edge_data_matrix, simIdx=i, minStartIdx=0, sample_freq=sample_freq)\n",
    "        r_data_matrix[:, :, i] = r_vals\n",
    "\n",
    "    return r_data_matrix\n",
    "\n",
    "\n",
    "# %%\n",
    "rd_2161 = getRValuesAllSims(ed_2161, sample_freq=args.ds)\n",
    "print(rd_2161.shape)\n",
    "# %%\n",
    "# we are removing some data where the edge detection is not necessarily super reliable.\n",
    "sims_to_remove = np.array([33, 39, 63, 73, 113, 128, 131, 142, 193, 218, 253, 264, 273, 312, 313, 324])\n",
    "\n",
    "# %%\n",
    "sd_modified = np.setdiff1d(sd_2161, sims_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7be3925a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183 39 40\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import Generator, PCG64\n",
    "# rng = Generator(PCG64())\n",
    "rng = np.random.default_rng(seed=202310)\n",
    "\n",
    "nTrain = int(np.floor(0.7 * len(sd_modified)))\n",
    "nCalib = int(np.floor(0.15 * len(sd_modified)))\n",
    "nTest = len(sd_modified) - nTrain - nCalib\n",
    "\n",
    "print(nTrain, nCalib, nTest)\n",
    "\n",
    "sd_train = np.sort(rng.choice(sd_modified, nTrain, replace=False))\n",
    "sd_calib = np.sort(rng.choice(np.setdiff1d(sd_modified, sd_train), nCalib, replace=False))\n",
    "sd_test = np.setdiff1d(sd_modified, np.sort(np.concatenate((sd_train, sd_calib), axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bac9c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_sd_train_idx = np.array([np.where(sd_2161 == i)[0][0] for i in sd_train])\n",
    "orig_sd_test_idx = np.array([np.where(sd_2161 == i)[0][0] for i in sd_test])\n",
    "orig_sd_calib_idx = np.array([np.where(sd_2161 == i)[0][0] for i in sd_calib])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a63ec48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(orig_sd_train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb067967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cbb0007",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = rd_2161[:, :, orig_sd_train_idx]\n",
    "y_test = rd_2161[:, :, orig_sd_test_idx]\n",
    "y_calib = rd_2161[:, :, orig_sd_calib_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf294591",
   "metadata": {},
   "outputs": [],
   "source": [
    "tMinTrain = []\n",
    "tMaxTrain = []\n",
    "\n",
    "tMinTrainIdx=[]\n",
    "tMaxTrainIdx=[]\n",
    "\n",
    "dtTrain = []\n",
    "yMinTrain = []\n",
    "yMaxTrain = []\n",
    "\n",
    "tMinTest = []\n",
    "tMaxTest = []\n",
    "dtTest = []\n",
    "\n",
    "tMinCalib = []\n",
    "tMaxCalib = []\n",
    "dtCalib = []\n",
    "\n",
    "for sidx in orig_sd_train_idx:\n",
    "    \n",
    "    r_sim = rd_2161[:, :, sidx]\n",
    "    \n",
    "    tMinIdx, tMin, tMaxIdx, tMax = edut.getTMinTMax(ed_2161, simIdx = sidx)\n",
    "\n",
    "    r_sim_valid = r_sim[tMinIdx:(tMaxIdx + 1), :]\n",
    "    \n",
    "    tMinTrain.append(tMin)\n",
    "    tMaxTrain.append(tMax)\n",
    "\n",
    "    tMinTrainIdx.append(tMinIdx)\n",
    "    tMaxTrainIdx.append(tMaxIdx)\n",
    "\n",
    "    \n",
    "    yMinTrain.append(r_sim_valid.min())\n",
    "    yMaxTrain.append(r_sim_valid.max())\n",
    "    \n",
    "    tAllScaled = (np.arange(tMin, tMax + 2, step=2) - tMin) / (tMax - tMin)\n",
    "    \n",
    "    dtTrain.append(tAllScaled[1] - tAllScaled[0])\n",
    "    \n",
    "    \n",
    "for sidx in orig_sd_test_idx:\n",
    "    \n",
    "    r_sim = rd_2161[:, :, sidx]\n",
    "    \n",
    "    tMinIdx, tMin, tMaxIdx, tMax = edut.getTMinTMax(ed_2161, simIdx = sidx)\n",
    "\n",
    "    r_sim_valid = r_sim[tMinIdx:(tMaxIdx + 1), :]\n",
    "    \n",
    "    tMinTest.append(tMin)\n",
    "    tMaxTest.append(tMax)\n",
    "        \n",
    "    tAllScaled = (np.arange(tMin, tMax + 2, step=2) - tMin) / (tMax - tMin)\n",
    "    \n",
    "    dtTest.append(tAllScaled[1] - tAllScaled[0])\n",
    "    \n",
    "    \n",
    "    \n",
    "for sidx in orig_sd_calib_idx:    \n",
    "    r_sim = rd_2161[:, :, sidx]\n",
    "    \n",
    "    tMinIdx, tMin, tMaxIdx, tMax = edut.getTMinTMax(ed_2161, simIdx = sidx)\n",
    "\n",
    "    r_sim_valid = r_sim[tMinIdx:(tMaxIdx + 1), :]\n",
    "    \n",
    "    tMinCalib.append(tMin)\n",
    "    tMaxCalib.append(tMax)\n",
    "        \n",
    "    tAllScaled = (np.arange(tMin, tMax + 2, step=2) - tMin) / (tMax - tMin)\n",
    "    \n",
    "    dtCalib.append(tAllScaled[1] - tAllScaled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "476e0a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW NORMALIZE YTRAIN AND YTEST\n",
    "yMinTrainAll = np.array(yMinTrain).min()\n",
    "yMaxTrainAll = np.array(yMaxTrain).max()\n",
    "\n",
    "yMinTrainAll, yMaxTrainAll\n",
    "\n",
    "# %%\n",
    "y_train_normalized = (y_train - yMinTrainAll) / (yMaxTrainAll - yMinTrainAll)\n",
    "y_test_normalized = (y_test - yMinTrainAll) / (yMaxTrainAll - yMinTrainAll)\n",
    "\n",
    "# %%\n",
    "y_calib_normalized = (y_calib - yMinTrainAll) / (yMaxTrainAll - yMinTrainAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80bec38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278, 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "cme_params_norm = pd.read_csv(\"./CMEParams2161_Scaled.csv\", index_col=0)\n",
    "cme_params_norm\n",
    "\n",
    "# %%\n",
    "cme_params_to_augment = cme_params_norm.to_numpy()\n",
    "cme_params_to_augment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a6bc2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = rd_2161.shape[1]\n",
    "param_dim = 9\n",
    "input_dim, param_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1717bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_r = np.zeros((rd_2161.shape[0], input_dim + param_dim, rd_2161.shape[2]))\n",
    "augmented_r[:, :input_dim, orig_sd_train_idx] = y_train_normalized\n",
    "augmented_r[:, :input_dim, orig_sd_test_idx] = y_test_normalized\n",
    "augmented_r[:, :input_dim, orig_sd_calib_idx] = y_calib_normalized\n",
    "for iii in range(rd_2161.shape[2]):\n",
    "    augmented_r[:, (input_dim):, iii] = cme_params_to_augment[iii, :]\n",
    "    \n",
    "    \n",
    "aug_y_train = augmented_r[:, :, orig_sd_train_idx]\n",
    "aug_y_test = augmented_r[:, :, orig_sd_test_idx]\n",
    "aug_y_calib = augmented_r[:, :, orig_sd_calib_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6859ef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_network_weights_xavier_normal(net):\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            nn.init.constant_(m.bias, val=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a7359f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Encoder-Decoder PNODE Now\n",
    "class ODENet(nn.Module):\n",
    "    def __init__(self, \n",
    "                 latent_dim, \n",
    "                 param_dim,\n",
    "                 n_layers=1,\n",
    "                 n_units=100,\n",
    "                 nonlinear=nn.ELU):\n",
    "    \n",
    "        super(ODENet, self).__init__()\n",
    "        layers = [nn.Linear(latent_dim + param_dim, n_units)]\n",
    "        for i in range(n_layers - 1):\n",
    "            layers.append(nonlinear())\n",
    "            layers.append(nn.Linear(n_units, n_units))\n",
    "\n",
    "        layers.append(nonlinear())\n",
    "        layers.append(nn.Linear(n_units, latent_dim))  \n",
    "        odenet = nn.Sequential(*layers)\n",
    "\n",
    "        init_network_weights_xavier_normal(odenet)\n",
    "\n",
    "        self.odenet = odenet\n",
    "        self.latent_dim = latent_dim\n",
    "    \n",
    "    def forward(self, t, y):\n",
    "        \n",
    "        output = torch.cat((self.odenet(y),\n",
    "                    torch.zeros_like(y[:, self.latent_dim:])), \n",
    "                    -1)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class PNODE_Conv(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim,\n",
    "                 latent_dim,\n",
    "                 param_dim, \n",
    "                 n_layers=1, \n",
    "                 n_units=100,\n",
    "                 nonlinear=nn.ELU):\n",
    "        super(PNODE_Conv, self).__init__()\n",
    "        \n",
    "        encoder = nn.Sequential(nn.ZeroPad2d((7,8,0,0)),\n",
    "                                nn.Conv1d(1,8,16,stride=2,padding=0),\n",
    "                                nn.ELU(),\n",
    "                                nn.ZeroPad2d((3,4,0,0)),\n",
    "                                nn.Conv1d(8,16,8,stride=4,padding=0),\n",
    "                                nn.ELU(),\n",
    "                                nn.ZeroPad2d((1,2,0,0)),\n",
    "                                nn.Conv1d(16,32,4,stride=4,padding=0),\n",
    "                                nn.ELU(),\n",
    "                                nn.ZeroPad2d((1,2,0,0)),\n",
    "                                nn.Conv1d(32,64,4,stride=4,padding=0),\n",
    "                                nn.ELU(),\n",
    "                                nn.Flatten(),\n",
    "                                nn.Linear(128,latent_dim), \n",
    "                                nn.ELU()\n",
    "                                )\n",
    "        \n",
    "\n",
    "        \n",
    "        decoder_mlp = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 80),\n",
    "            nn.ELU())\n",
    "        decoder_conv = nn.Sequential(nn.ConvTranspose1d(40, 20, 4, stride=4),\n",
    "                            nn.ELU(),\n",
    "                            nn.ConvTranspose1d(20, 10, 4, stride=4),\n",
    "                            nn.ELU(),\n",
    "                            nn.ConvTranspose1d(10, 5, 3, stride=3, padding=8),\n",
    "                            nn.ELU(),\n",
    "                            nn.ConvTranspose1d(5, 1, 6, stride=2, padding=2))\n",
    "        \n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.encoder=encoder\n",
    "        self.pnode=ODENet(latent_dim, param_dim).to(device)\n",
    "        self.decoder_mlp = decoder_mlp\n",
    "        self.decoder_conv = decoder_conv\n",
    "        \n",
    "        init_network_weights_xavier_normal(encoder)\n",
    "        init_network_weights_xavier_normal(decoder_mlp)\n",
    "        init_network_weights_xavier_normal(decoder_conv)\n",
    "        \n",
    "        \n",
    "    def forward(self, t, y):\n",
    "        y_init = y[:, None, :self.input_dim].reshape((-1, 1, self.input_dim))\n",
    "        init_latent = self.encoder(y_init).reshape((1, -1, self.latent_dim))\n",
    "        init_latent = torch.cat((init_latent, y[:, None, self.input_dim:]),-1)\n",
    "        latent_states = odeint(self.pnode, init_latent[0, :, :], t)\n",
    "        #         ntraj, nbatch, _  = latent_states.shape\n",
    "        latent_mlp = self.decoder_mlp(latent_states[:, :, :self.latent_dim])\n",
    "        latent_mlp = torch.permute(latent_mlp, (1, 0, 2))\n",
    "        latent_mlp = latent_mlp[None, :, :, :]\n",
    "        nbatch, ntraj, nt, _ = latent_mlp.shape\n",
    "        latent_mlp = latent_mlp.reshape((-1, 40, 2))\n",
    "        pred_sol = self.decoder_conv(latent_mlp)\n",
    "        pred_sol = pred_sol.reshape((nbatch, ntraj, nt, 160))\n",
    "        \n",
    "        return pred_sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7235f8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnode_conv = PNODE_Conv(input_dim=160, latent_dim=15, param_dim=9).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "854c9ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "22958\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adamax(pnode_conv.parameters(), lr=args.lr)\n",
    "\n",
    "print(args.lr)\n",
    "pEncoder = edut.count_parameters(pnode_conv.encoder)\n",
    "pPNODE = edut.count_parameters(pnode_conv.pnode)\n",
    "pDecoder = edut.count_parameters(pnode_conv.decoder_mlp) + edut.count_parameters(pnode_conv.decoder_conv)\n",
    "\n",
    "print(pEncoder + pPNODE + pDecoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbe235b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74807\n",
      "experiments/experiment_74807.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<RootLogger root (INFO)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edut.makedirs(args.save)\n",
    "\n",
    "if args.load is not None:\n",
    "    experimentID = args.load\n",
    "else:\n",
    "    experimentID = int(SystemRandom().random()*100000)\n",
    "print(experimentID)\n",
    "\n",
    "ckpt_path = os.path.join(args.save, \"experiment_\" + str(experimentID) + '.ckpt')\n",
    "print(ckpt_path)\n",
    "\n",
    "# %%\n",
    "logger = get_logger(logpath=os.path.join(logdir, \"expt_normalized_pnode_siam2.log\"))\n",
    "logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e87c6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajivani/WLROM_new/EdgeSS\n",
      "PNODE_Conv(\n",
      "  (encoder): Sequential(\n",
      "    (0): ZeroPad2d((7, 8, 0, 0))\n",
      "    (1): Conv1d(1, 8, kernel_size=(16,), stride=(2,))\n",
      "    (2): ELU(alpha=1.0)\n",
      "    (3): ZeroPad2d((3, 4, 0, 0))\n",
      "    (4): Conv1d(8, 16, kernel_size=(8,), stride=(4,))\n",
      "    (5): ELU(alpha=1.0)\n",
      "    (6): ZeroPad2d((1, 2, 0, 0))\n",
      "    (7): Conv1d(16, 32, kernel_size=(4,), stride=(4,))\n",
      "    (8): ELU(alpha=1.0)\n",
      "    (9): ZeroPad2d((1, 2, 0, 0))\n",
      "    (10): Conv1d(32, 64, kernel_size=(4,), stride=(4,))\n",
      "    (11): ELU(alpha=1.0)\n",
      "    (12): Flatten(start_dim=1, end_dim=-1)\n",
      "    (13): Linear(in_features=128, out_features=15, bias=True)\n",
      "    (14): ELU(alpha=1.0)\n",
      "  )\n",
      "  (pnode): ODENet(\n",
      "    (odenet): Sequential(\n",
      "      (0): Linear(in_features=24, out_features=100, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Linear(in_features=100, out_features=15, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder_mlp): Sequential(\n",
      "    (0): Linear(in_features=15, out_features=80, bias=True)\n",
      "    (1): ELU(alpha=1.0)\n",
      "  )\n",
      "  (decoder_conv): Sequential(\n",
      "    (0): ConvTranspose1d(40, 20, kernel_size=(4,), stride=(4,))\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): ConvTranspose1d(20, 10, kernel_size=(4,), stride=(4,))\n",
      "    (3): ELU(alpha=1.0)\n",
      "    (4): ConvTranspose1d(10, 5, kernel_size=(3,), stride=(3,), padding=(8,))\n",
      "    (5): ELU(alpha=1.0)\n",
      "    (6): ConvTranspose1d(5, 1, kernel_size=(6,), stride=(2,), padding=(2,))\n",
      "  )\n",
      ")\n",
      "Number of parameters: 22958\n",
      "{'niters': 50, 'lr': 0.01, 'batch_size': 4, 'batch_time': 5, 'nsims_per_batch': 1, 'nepochs': 300, 'save': 'experiments/', 'load': None, 'random_seed': 1123, 'pnode': True, 'node_layers': 3, 'units': 90, 'nParamsToUse': 9, 'ds': 1}\n",
      "Train Idx\n",
      "[ 31  32  34  37  38  40  41  44  45  46  49  50  51  53  54  56  57  58\n",
      "  59  61  62  67  69  70  71  72  75  76  77  78  79  82  83  84  85  86\n",
      "  87  88  89  90  91  92  93  94  95  97  98 101 103 104 105 107 110 111\n",
      " 112 115 118 120 123 126 127 132 134 135 136 138 139 140 141 143 144 145\n",
      " 146 147 148 150 151 152 153 154 155 156 157 159 160 161 163 164 166 171\n",
      " 172 173 175 176 177 178 180 183 184 185 190 191 192 198 199 201 202 203\n",
      " 204 205 206 213 214 215 216 217 219 220 221 222 223 224 226 228 229 230\n",
      " 231 232 233 234 235 236 238 239 240 241 242 243 246 247 249 251 252 254\n",
      " 255 259 260 261 265 269 271 274 275 276 278 280 281 282 283 284 286 288\n",
      " 290 293 294 295 296 299 300 303 305 307 314 316 317 318 319 321 322 326\n",
      " 327 328 329]\n",
      "Calib Idx\n",
      "[ 36  42  47  48  52  60  64  65  74  80 100 102 121 129 130 149 162 168\n",
      " 169 179 196 197 209 210 211 225 227 262 263 272 289 291 297 298 301 304\n",
      " 315 320 325]\n",
      "Test Idx\n",
      "[ 35  43  66  68  81  96  99 106 108 114 119 122 124 133 158 174 181 186\n",
      " 188 194 200 208 212 237 244 248 256 257 258 266 267 268 277 279 287 292\n",
      " 302 306 311 323]\n",
      "Checkpoint Path\n",
      "experiments/experiment_74807.ckpt\n",
      "Input Dim: \n",
      "160\n",
      "Param Dim: \n",
      "9\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "logger.info(os.getcwd())\n",
    "logger.info(pnode_conv)\n",
    "logger.info(\"Number of parameters: {}\".format(pEncoder + pPNODE + pDecoder))\n",
    "logger.info(vars(args))\n",
    "logger.info(\"Train Idx\")\n",
    "logger.info(sd_train)\n",
    "logger.info(\"Calib Idx\")\n",
    "logger.info(sd_calib)\n",
    "logger.info(\"Test Idx\")\n",
    "logger.info(sd_test)\n",
    "logger.info(\"Checkpoint Path\")\n",
    "logger.info(ckpt_path)\n",
    "logger.info(\"Input Dim: \")\n",
    "logger.info(input_dim)\n",
    "logger.info(\"Param Dim: \")\n",
    "logger.info(param_dim)\n",
    "logger.info(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a4a242d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([90])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_steps = torch.Tensor(np.linspace(0, 1, rd_2161.shape[0]))\n",
    "time_steps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cee713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def get_data_for_sim(sidx, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Supply sidx from either orig_sd_train_idx or orig_sd_test_idx\n",
    "    Based on that, index augmented r dataset, and return relevant training data\n",
    "    as well as training time.\n",
    "    \"\"\"\n",
    "    tMinIdx, tMin, tMaxIdx, tMax = edut.getTMinTMax(ed_2161, simIdx = sidx)\n",
    "    \n",
    "    #     valid_times = np.arange(tMin, tMax + 2, step=2)\n",
    "        \n",
    "    #     tAllScaled = (valid_times - tMin) / (tMax - tMin)\n",
    "    \n",
    "    time_steps = np.linspace(0, 1, rd_2161.shape[0])\n",
    "    tAllScaled = time_steps[:(tMaxIdx - tMinIdx + 1)]\n",
    "    \n",
    "    r_sim = augmented_r[tMinIdx:(tMaxIdx + 1), :, sidx]\n",
    "    \n",
    "    y0_train_torch = torch.from_numpy(np.float32(r_sim[0, :])).reshape((1, len(r_sim[0, :]))).to(device)\n",
    "    t_train_torch = torch.Tensor(tAllScaled).to(device)\n",
    "    y_train_torch = torch.Tensor(r_sim).to(device)\n",
    "    \n",
    "    return y0_train_torch, t_train_torch, y_train_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcbf3ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_freq=25\n",
    "\n",
    "def update_learning_rate(optimizer, decay_rate = 0.999, lowest = 1e-3):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        lr = param_group['lr']\n",
    "        lr = max(lr * decay_rate, lowest)\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87038f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_ids_all = np.array([i for i in range(len(orig_sd_train_idx))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577abe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_sd_train_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3bb99cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_ids_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f3d09829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_ids_to_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd862f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_ids_to_train = np.sort(rng.choice(sim_ids_all, args.nsims_per_batch, replace=False))\n",
    "# y0_data, tt_data, ytt_data = get_data_for_sim(sim_ids_to_train[0], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3b94905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y0_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "94efce0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# il = pnode_conv.encoder(y0_data[:, None, :input_dim]).reshape((1, -1, 15))\n",
    "# il2 = torch.cat((il, y0_data[:, None, input_dim:]),-1)\n",
    "# il2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee7c0fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls = odeint(pnode_conv.pnode, il2[0, :, :], tt_data)\n",
    "# ls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68643c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent_mlp = pnode_conv.decoder_mlp(ls[:, :, :15])\n",
    "# latent_mlp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "573e2901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y0_data.reshape((1, 1, input_dim + param_dim))[:, :, :input_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2bee3353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.squeeze(pnode_conv(tt_data, y0_data)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dcbfef46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01|Iteration 001|Val Losses Agg 11.6788|Sim 117|Train loss batch 0.1958|\n",
      "Epoch 01|Iteration 002|Val Losses Agg 9.6814|Sim 117|Train loss batch 0.4928|\n",
      "Epoch 01|Iteration 003|Val Losses Agg 7.8701|Sim 117|Train loss batch 0.4337|\n",
      "Epoch 01|Iteration 004|Val Losses Agg 7.0431|Sim 117|Train loss batch 0.3618|\n",
      "Epoch 01|Iteration 005|Val Losses Agg 9.1988|Sim 117|Train loss batch 0.2825|\n",
      "Epoch 01|Iteration 006|Val Losses Agg 12.9266|Sim 117|Train loss batch 0.2407|\n",
      "Epoch 01|Iteration 007|Val Losses Agg 13.1310|Sim 117|Train loss batch 0.2597|\n",
      "Epoch 01|Iteration 008|Val Losses Agg 10.9804|Sim 117|Train loss batch 0.2433|\n",
      "Epoch 01|Iteration 009|Val Losses Agg 9.1127|Sim 117|Train loss batch 0.2035|\n",
      "Epoch 01|Iteration 010|Val Losses Agg 8.2023|Sim 117|Train loss batch 0.1881|\n",
      "Epoch 01|Iteration 011|Val Losses Agg 7.9266|Sim 117|Train loss batch 0.1866|\n",
      "Epoch 01|Iteration 012|Val Losses Agg 8.1385|Sim 117|Train loss batch 0.1824|\n",
      "Epoch 01|Iteration 013|Val Losses Agg 8.9081|Sim 117|Train loss batch 0.1701|\n",
      "Epoch 01|Iteration 014|Val Losses Agg 10.3892|Sim 117|Train loss batch 0.1511|\n",
      "Epoch 01|Iteration 015|Val Losses Agg 12.4972|Sim 117|Train loss batch 0.1308|\n",
      "Epoch 01|Iteration 016|Val Losses Agg 14.1308|Sim 117|Train loss batch 0.1195|\n",
      "Epoch 01|Iteration 017|Val Losses Agg 13.7738|Sim 117|Train loss batch 0.1135|\n",
      "Epoch 01|Iteration 018|Val Losses Agg 11.8382|Sim 117|Train loss batch 0.0849|\n",
      "Epoch 01|Iteration 019|Val Losses Agg 10.7927|Sim 117|Train loss batch 0.0598|\n",
      "Epoch 01|Iteration 020|Val Losses Agg 12.0199|Sim 117|Train loss batch 0.0743|\n",
      "Epoch 01|Iteration 021|Val Losses Agg 14.7960|Sim 117|Train loss batch 0.0516|\n",
      "Epoch 01|Iteration 022|Val Losses Agg 15.7078|Sim 117|Train loss batch 0.0464|\n",
      "Epoch 01|Iteration 023|Val Losses Agg 14.3808|Sim 117|Train loss batch 0.0583|\n",
      "Epoch 01|Iteration 024|Val Losses Agg 12.6327|Sim 117|Train loss batch 0.0436|\n",
      "Epoch 01|Iteration 025|Val Losses Agg 12.2686|Sim 117|Train loss batch 0.0474|\n",
      "Epoch 01|Iteration 026|Val Losses Agg 13.5752|Sim 117|Train loss batch 0.0496|\n",
      "Epoch 01|Iteration 027|Val Losses Agg 15.5416|Sim 117|Train loss batch 0.0327|\n",
      "Epoch 01|Iteration 028|Val Losses Agg 15.5750|Sim 117|Train loss batch 0.0384|\n",
      "Epoch 01|Iteration 029|Val Losses Agg 13.8036|Sim 117|Train loss batch 0.0377|\n",
      "Epoch 01|Iteration 030|Val Losses Agg 12.9521|Sim 117|Train loss batch 0.0275|\n",
      "Epoch 01|Iteration 031|Val Losses Agg 13.7792|Sim 117|Train loss batch 0.0340|\n",
      "Epoch 01|Iteration 032|Val Losses Agg 15.0675|Sim 117|Train loss batch 0.0249|\n",
      "Epoch 01|Iteration 033|Val Losses Agg 14.7279|Sim 117|Train loss batch 0.0324|\n",
      "Epoch 01|Iteration 034|Val Losses Agg 13.3108|Sim 117|Train loss batch 0.0265|\n",
      "Epoch 01|Iteration 035|Val Losses Agg 13.5530|Sim 117|Train loss batch 0.0254|\n",
      "Epoch 01|Iteration 036|Val Losses Agg 15.1194|Sim 117|Train loss batch 0.0230|\n",
      "Epoch 01|Iteration 037|Val Losses Agg 14.9589|Sim 117|Train loss batch 0.0246|\n",
      "Epoch 01|Iteration 038|Val Losses Agg 13.5181|Sim 117|Train loss batch 0.0227|\n",
      "Epoch 01|Iteration 039|Val Losses Agg 13.4050|Sim 117|Train loss batch 0.0221|\n",
      "Epoch 01|Iteration 040|Val Losses Agg 14.6064|Sim 117|Train loss batch 0.0212|\n",
      "Epoch 01|Iteration 041|Val Losses Agg 14.4070|Sim 117|Train loss batch 0.0199|\n",
      "Epoch 01|Iteration 042|Val Losses Agg 13.3371|Sim 117|Train loss batch 0.0177|\n",
      "Epoch 01|Iteration 043|Val Losses Agg 13.7186|Sim 117|Train loss batch 0.0198|\n",
      "Epoch 01|Iteration 044|Val Losses Agg 14.6407|Sim 117|Train loss batch 0.0160|\n",
      "Epoch 01|Iteration 045|Val Losses Agg 14.0668|Sim 117|Train loss batch 0.0196|\n",
      "Epoch 01|Iteration 046|Val Losses Agg 13.1623|Sim 117|Train loss batch 0.0143|\n",
      "Epoch 01|Iteration 047|Val Losses Agg 13.7572|Sim 117|Train loss batch 0.0204|\n",
      "Epoch 01|Iteration 048|Val Losses Agg 14.6022|Sim 117|Train loss batch 0.0150|\n",
      "Epoch 01|Iteration 049|Val Losses Agg 13.8223|Sim 117|Train loss batch 0.0190|\n",
      "Epoch 01|Iteration 050|Val Losses Agg 13.4349|Sim 117|Train loss batch 0.0132|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving check point...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02|Iteration 001|Val Losses Agg 11.3733|Sim 138|Train loss batch 0.4376|\n",
      "Epoch 02|Iteration 002|Val Losses Agg 10.9402|Sim 138|Train loss batch 0.0571|\n",
      "Epoch 02|Iteration 003|Val Losses Agg 11.8333|Sim 138|Train loss batch 0.0636|\n",
      "Epoch 02|Iteration 004|Val Losses Agg 14.0371|Sim 138|Train loss batch 0.0404|\n",
      "Epoch 02|Iteration 005|Val Losses Agg 15.4204|Sim 138|Train loss batch 0.0204|\n",
      "Epoch 02|Iteration 006|Val Losses Agg 15.0491|Sim 138|Train loss batch 0.0452|\n",
      "Epoch 02|Iteration 007|Val Losses Agg 13.2435|Sim 138|Train loss batch 0.0391|\n",
      "Epoch 02|Iteration 008|Val Losses Agg 11.8279|Sim 138|Train loss batch 0.0171|\n",
      "Epoch 02|Iteration 009|Val Losses Agg 11.8169|Sim 138|Train loss batch 0.0332|\n",
      "Epoch 02|Iteration 010|Val Losses Agg 13.0971|Sim 138|Train loss batch 0.0341|\n",
      "Epoch 02|Iteration 011|Val Losses Agg 14.5377|Sim 138|Train loss batch 0.0153|\n",
      "Epoch 02|Iteration 012|Val Losses Agg 14.4559|Sim 138|Train loss batch 0.0290|\n",
      "Epoch 02|Iteration 013|Val Losses Agg 13.0635|Sim 138|Train loss batch 0.0270|\n",
      "Epoch 02|Iteration 014|Val Losses Agg 12.1848|Sim 138|Train loss batch 0.0145|\n",
      "Epoch 02|Iteration 015|Val Losses Agg 12.5546|Sim 138|Train loss batch 0.0255|\n",
      "Epoch 02|Iteration 016|Val Losses Agg 13.9485|Sim 138|Train loss batch 0.0198|\n",
      "Epoch 02|Iteration 017|Val Losses Agg 14.3412|Sim 138|Train loss batch 0.0170|\n",
      "Epoch 02|Iteration 018|Val Losses Agg 13.4420|Sim 138|Train loss batch 0.0213|\n",
      "Epoch 02|Iteration 019|Val Losses Agg 12.6085|Sim 138|Train loss batch 0.0120|\n",
      "Epoch 02|Iteration 020|Val Losses Agg 13.1688|Sim 138|Train loss batch 0.0218|\n",
      "Epoch 02|Iteration 021|Val Losses Agg 14.5815|Sim 138|Train loss batch 0.0127|\n",
      "Epoch 02|Iteration 022|Val Losses Agg 14.4386|Sim 138|Train loss batch 0.0222|\n",
      "Epoch 02|Iteration 023|Val Losses Agg 12.9924|Sim 138|Train loss batch 0.0195|\n",
      "Epoch 02|Iteration 024|Val Losses Agg 12.9012|Sim 138|Train loss batch 0.0161|\n",
      "Epoch 02|Iteration 025|Val Losses Agg 14.1179|Sim 138|Train loss batch 0.0180|\n",
      "Epoch 02|Iteration 026|Val Losses Agg 14.2152|Sim 138|Train loss batch 0.0135|\n",
      "Epoch 02|Iteration 027|Val Losses Agg 13.1506|Sim 138|Train loss batch 0.0145|\n",
      "Epoch 02|Iteration 028|Val Losses Agg 13.3713|Sim 138|Train loss batch 0.0140|\n",
      "Epoch 02|Iteration 029|Val Losses Agg 14.3934|Sim 138|Train loss batch 0.0110|\n",
      "Epoch 02|Iteration 030|Val Losses Agg 13.9824|Sim 138|Train loss batch 0.0166|\n",
      "Epoch 02|Iteration 031|Val Losses Agg 12.8467|Sim 138|Train loss batch 0.0108|\n",
      "Epoch 02|Iteration 032|Val Losses Agg 13.1889|Sim 138|Train loss batch 0.0201|\n",
      "Epoch 02|Iteration 033|Val Losses Agg 14.7676|Sim 138|Train loss batch 0.0138|\n",
      "Epoch 02|Iteration 034|Val Losses Agg 14.6788|Sim 138|Train loss batch 0.0229|\n",
      "Epoch 02|Iteration 035|Val Losses Agg 13.1401|Sim 138|Train loss batch 0.0212|\n",
      "Epoch 02|Iteration 036|Val Losses Agg 13.0146|Sim 138|Train loss batch 0.0142|\n",
      "Epoch 02|Iteration 037|Val Losses Agg 14.2354|Sim 138|Train loss batch 0.0162|\n",
      "Epoch 02|Iteration 038|Val Losses Agg 14.1600|Sim 138|Train loss batch 0.0145|\n",
      "Epoch 02|Iteration 039|Val Losses Agg 12.9665|Sim 138|Train loss batch 0.0136|\n",
      "Epoch 02|Iteration 040|Val Losses Agg 13.1291|Sim 138|Train loss batch 0.0154|\n",
      "Epoch 02|Iteration 041|Val Losses Agg 14.2714|Sim 138|Train loss batch 0.0126|\n",
      "Epoch 02|Iteration 042|Val Losses Agg 14.0574|Sim 138|Train loss batch 0.0163|\n",
      "Epoch 02|Iteration 043|Val Losses Agg 12.8887|Sim 138|Train loss batch 0.0127|\n",
      "Epoch 02|Iteration 044|Val Losses Agg 13.1636|Sim 138|Train loss batch 0.0171|\n",
      "Epoch 02|Iteration 045|Val Losses Agg 14.5282|Sim 138|Train loss batch 0.0124|\n",
      "Epoch 02|Iteration 046|Val Losses Agg 14.3525|Sim 138|Train loss batch 0.0196|\n",
      "Epoch 02|Iteration 047|Val Losses Agg 12.9302|Sim 138|Train loss batch 0.0167|\n",
      "Epoch 02|Iteration 048|Val Losses Agg 12.8917|Sim 138|Train loss batch 0.0159|\n",
      "Epoch 02|Iteration 049|Val Losses Agg 14.0907|Sim 138|Train loss batch 0.0165|\n",
      "Epoch 02|Iteration 050|Val Losses Agg 14.1425|Sim 138|Train loss batch 0.0130|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving check point...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03|Iteration 001|Val Losses Agg 12.5255|Sim 035|Train loss batch 0.4197|\n",
      "Epoch 03|Iteration 002|Val Losses Agg 12.4043|Sim 035|Train loss batch 0.0232|\n",
      "Epoch 03|Iteration 003|Val Losses Agg 13.5908|Sim 035|Train loss batch 0.0248|\n",
      "Epoch 03|Iteration 004|Val Losses Agg 14.3992|Sim 035|Train loss batch 0.0102|\n",
      "Epoch 03|Iteration 005|Val Losses Agg 13.7757|Sim 035|Train loss batch 0.0203|\n",
      "Epoch 03|Iteration 006|Val Losses Agg 12.5010|Sim 035|Train loss batch 0.0110|\n",
      "Epoch 03|Iteration 007|Val Losses Agg 12.6084|Sim 035|Train loss batch 0.0205|\n",
      "Epoch 03|Iteration 008|Val Losses Agg 13.9095|Sim 035|Train loss batch 0.0183|\n",
      "Epoch 03|Iteration 009|Val Losses Agg 14.2059|Sim 035|Train loss batch 0.0134|\n",
      "Epoch 03|Iteration 010|Val Losses Agg 13.2135|Sim 035|Train loss batch 0.0175|\n",
      "Epoch 03|Iteration 011|Val Losses Agg 12.9172|Sim 035|Train loss batch 0.0095|\n",
      "Epoch 03|Iteration 012|Val Losses Agg 13.8056|Sim 035|Train loss batch 0.0136|\n",
      "Epoch 03|Iteration 013|Val Losses Agg 13.8559|Sim 035|Train loss batch 0.0107|\n",
      "Epoch 03|Iteration 014|Val Losses Agg 13.0795|Sim 035|Train loss batch 0.0107|\n",
      "Epoch 03|Iteration 015|Val Losses Agg 13.4568|Sim 035|Train loss batch 0.0114|\n",
      "Epoch 03|Iteration 016|Val Losses Agg 14.1240|Sim 035|Train loss batch 0.0077|\n",
      "Epoch 03|Iteration 017|Val Losses Agg 13.5062|Sim 035|Train loss batch 0.0127|\n",
      "Epoch 03|Iteration 018|Val Losses Agg 13.3804|Sim 035|Train loss batch 0.0080|\n",
      "Epoch 03|Iteration 019|Val Losses Agg 14.3163|Sim 035|Train loss batch 0.0093|\n",
      "Epoch 03|Iteration 020|Val Losses Agg 13.8345|Sim 035|Train loss batch 0.0140|\n",
      "Epoch 03|Iteration 021|Val Losses Agg 13.0016|Sim 035|Train loss batch 0.0084|\n",
      "Epoch 03|Iteration 022|Val Losses Agg 13.5643|Sim 035|Train loss batch 0.0160|\n",
      "Epoch 03|Iteration 023|Val Losses Agg 14.5783|Sim 035|Train loss batch 0.0074|\n",
      "Epoch 03|Iteration 024|Val Losses Agg 14.0259|Sim 035|Train loss batch 0.0188|\n",
      "Epoch 03|Iteration 025|Val Losses Agg 12.6957|Sim 035|Train loss batch 0.0097|\n",
      "Epoch 03|Iteration 026|Val Losses Agg 12.8253|Sim 035|Train loss batch 0.0226|\n",
      "Epoch 03|Iteration 027|Val Losses Agg 14.2871|Sim 035|Train loss batch 0.0197|\n",
      "Epoch 03|Iteration 028|Val Losses Agg 14.2907|Sim 035|Train loss batch 0.0137|\n",
      "Epoch 03|Iteration 029|Val Losses Agg 12.9468|Sim 035|Train loss batch 0.0143|\n",
      "Epoch 03|Iteration 030|Val Losses Agg 13.0511|Sim 035|Train loss batch 0.0153|\n",
      "Epoch 03|Iteration 031|Val Losses Agg 14.3849|Sim 035|Train loss batch 0.0128|\n",
      "Epoch 03|Iteration 032|Val Losses Agg 14.1910|Sim 035|Train loss batch 0.0173|\n",
      "Epoch 03|Iteration 033|Val Losses Agg 12.7621|Sim 035|Train loss batch 0.0140|\n",
      "Epoch 03|Iteration 034|Val Losses Agg 12.7905|Sim 035|Train loss batch 0.0171|\n",
      "Epoch 03|Iteration 035|Val Losses Agg 14.1018|Sim 035|Train loss batch 0.0159|\n",
      "Epoch 03|Iteration 036|Val Losses Agg 14.0945|Sim 035|Train loss batch 0.0140|\n",
      "Epoch 03|Iteration 037|Val Losses Agg 12.8892|Sim 035|Train loss batch 0.0144|\n",
      "Epoch 03|Iteration 038|Val Losses Agg 12.8765|Sim 035|Train loss batch 0.0127|\n",
      "Epoch 03|Iteration 039|Val Losses Agg 13.9837|Sim 035|Train loss batch 0.0129|\n",
      "Epoch 03|Iteration 040|Val Losses Agg 13.8281|Sim 035|Train loss batch 0.0125|\n",
      "Epoch 03|Iteration 041|Val Losses Agg 12.8024|Sim 035|Train loss batch 0.0100|\n",
      "Epoch 03|Iteration 042|Val Losses Agg 13.1136|Sim 035|Train loss batch 0.0150|\n",
      "Epoch 03|Iteration 043|Val Losses Agg 14.3612|Sim 035|Train loss batch 0.0099|\n",
      "Epoch 03|Iteration 044|Val Losses Agg 14.0928|Sim 035|Train loss batch 0.0177|\n",
      "Epoch 03|Iteration 045|Val Losses Agg 12.6405|Sim 035|Train loss batch 0.0123|\n",
      "Epoch 03|Iteration 046|Val Losses Agg 12.6471|Sim 035|Train loss batch 0.0197|\n",
      "Epoch 03|Iteration 047|Val Losses Agg 13.9589|Sim 035|Train loss batch 0.0197|\n",
      "Epoch 03|Iteration 048|Val Losses Agg 14.1620|Sim 035|Train loss batch 0.0098|\n",
      "Epoch 03|Iteration 049|Val Losses Agg 13.0756|Sim 035|Train loss batch 0.0127|\n",
      "Epoch 03|Iteration 050|Val Losses Agg 13.3193|Sim 035|Train loss batch 0.0120|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving check point...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04|Iteration 001|Val Losses Agg 11.9253|Sim 165|Train loss batch 0.3973|\n",
      "Epoch 04|Iteration 002|Val Losses Agg 11.6534|Sim 165|Train loss batch 0.0334|\n",
      "Epoch 04|Iteration 003|Val Losses Agg 12.3190|Sim 165|Train loss batch 0.0363|\n",
      "Epoch 04|Iteration 004|Val Losses Agg 13.7457|Sim 165|Train loss batch 0.0205|\n",
      "Epoch 04|Iteration 005|Val Losses Agg 14.4196|Sim 165|Train loss batch 0.0168|\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sd_calib)):\n\u001b[1;32m     21\u001b[0m     y0_data, tt_data, ytt_data \u001b[38;5;241m=\u001b[39m get_data_for_sim(orig_sd_calib_idx[i], device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m---> 22\u001b[0m     val_pred_y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqueeze(\u001b[43mpnode_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtt_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0_data\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     23\u001b[0m     val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mabs(val_pred_y \u001b[38;5;241m-\u001b[39m ytt_data[:, :input_dim]))\n\u001b[1;32m     25\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{:02d}\u001b[39;00m\u001b[38;5;124m|Iteration \u001b[39m\u001b[38;5;132;01m{:03d}\u001b[39;00m\u001b[38;5;124m|Val Losses Agg \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m|Sim \u001b[39m\u001b[38;5;132;01m{:03d}\u001b[39;00m\u001b[38;5;124m|Train loss batch \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     26\u001b[0m         ep,\n\u001b[1;32m     27\u001b[0m         itr, \n\u001b[1;32m     28\u001b[0m         val_loss,\n\u001b[1;32m     29\u001b[0m         sim_ids_to_train[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     30\u001b[0m         losses\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[21], line 91\u001b[0m, in \u001b[0;36mPNODE_Conv.forward\u001b[0;34m(self, t, y)\u001b[0m\n\u001b[1;32m     89\u001b[0m init_latent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(y_init)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatent_dim))\n\u001b[1;32m     90\u001b[0m init_latent \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((init_latent, y[:, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dim:]),\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 91\u001b[0m latent_states \u001b[38;5;241m=\u001b[39m \u001b[43modeint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_latent\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m#         ntraj, nbatch, _  = latent_states.shape\u001b[39;00m\n\u001b[1;32m     93\u001b[0m latent_mlp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_mlp(latent_states[:, :, :\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatent_dim])\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torchdiffeq/_impl/adjoint.py:198\u001b[0m, in \u001b[0;36modeint_adjoint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn, adjoint_rtol, adjoint_atol, adjoint_method, adjoint_options, adjoint_params)\u001b[0m\n\u001b[1;32m    195\u001b[0m state_norm \u001b[38;5;241m=\u001b[39m options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    196\u001b[0m handle_adjoint_norm_(adjoint_options, shapes, state_norm)\n\u001b[0;32m--> 198\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[43mOdeintAdjointMethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjoint_rtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjoint_atol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m                                \u001b[49m\u001b[43madjoint_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjoint_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequires_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madjoint_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     solution \u001b[38;5;241m=\u001b[39m ans\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/autograd/function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    510\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torchdiffeq/_impl/adjoint.py:25\u001b[0m, in \u001b[0;36mOdeintAdjointMethod.forward\u001b[0;34m(ctx, shapes, func, y0, t, rtol, atol, method, options, event_fn, adjoint_rtol, adjoint_atol, adjoint_method, adjoint_options, t_requires_grad, *adjoint_params)\u001b[0m\n\u001b[1;32m     22\u001b[0m ctx\u001b[38;5;241m.\u001b[39mevent_mode \u001b[38;5;241m=\u001b[39m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 25\u001b[0m     ans \u001b[38;5;241m=\u001b[39m \u001b[43modeint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevent_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m         y \u001b[38;5;241m=\u001b[39m ans\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torchdiffeq/_impl/odeint.py:77\u001b[0m, in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     74\u001b[0m solver \u001b[38;5;241m=\u001b[39m SOLVERS[method](func\u001b[38;5;241m=\u001b[39mfunc, y0\u001b[38;5;241m=\u001b[39my0, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 77\u001b[0m     solution \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintegrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     event_t, solution \u001b[38;5;241m=\u001b[39m solver\u001b[38;5;241m.\u001b[39mintegrate_until_event(t[\u001b[38;5;241m0\u001b[39m], event_fn)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torchdiffeq/_impl/solvers.py:30\u001b[0m, in \u001b[0;36mAdaptiveStepsizeODESolver.integrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_before_integrate(t)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(t)):\n\u001b[0;32m---> 30\u001b[0m     solution[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_advance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m solution\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torchdiffeq/_impl/rk_common.py:194\u001b[0m, in \u001b[0;36mRKAdaptiveStepsizeODESolver._advance\u001b[0;34m(self, next_t)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m next_t \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt1:\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m n_steps \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_num_steps, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_num_steps exceeded (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_steps, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_num_steps)\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_adaptive_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrk_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     n_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _interp_evaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39minterp_coeff, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt0, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt1, next_t)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torchdiffeq/_impl/rk_common.py:255\u001b[0m, in \u001b[0;36mRKAdaptiveStepsizeODESolver._adaptive_step\u001b[0;34m(self, rk_state)\u001b[0m\n\u001b[1;32m    250\u001b[0m         dt \u001b[38;5;241m=\u001b[39m t1 \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# Must be arranged as doing all the step_t handling, then all the jump_t handling, in case we\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# trigger both. (i.e. interleaving them would be wrong.)\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m y1, f1, y1_error, k \u001b[38;5;241m=\u001b[39m \u001b[43m_runge_kutta_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtableau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtableau\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# dtypes:\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# y1.dtype == self.y0.dtype\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# f1.dtype == self.y0.dtype\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m#                     Error Ratio                      #\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m########################################################\u001b[39;00m\n\u001b[1;32m    265\u001b[0m error_ratio \u001b[38;5;241m=\u001b[39m _compute_error_ratio(y1_error, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrtol, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matol, y0, y1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torchdiffeq/_impl/rk_common.py:68\u001b[0m, in \u001b[0;36m_runge_kutta_step\u001b[0;34m(func, y0, f0, t0, dt, t1, tableau)\u001b[0m\n\u001b[1;32m     66\u001b[0m k \u001b[38;5;241m=\u001b[39m _UncheckedAssign\u001b[38;5;241m.\u001b[39mapply(k, f0, (\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (alpha_i, beta_i) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(tableau\u001b[38;5;241m.\u001b[39malpha, tableau\u001b[38;5;241m.\u001b[39mbeta)):\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m alpha_i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1.\u001b[39m:\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;66;03m# Always step to perturbing just before the end time, in case of discontinuities.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m         ti \u001b[38;5;241m=\u001b[39m t1\n\u001b[1;32m     71\u001b[0m         perturb \u001b[38;5;241m=\u001b[39m Perturb\u001b[38;5;241m.\u001b[39mPREV\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if args.load is not None:\n",
    "    edut.get_ckpt_model(ckpt_path, pnode_conv, device)\n",
    "else:\n",
    "    for ep in range(1, args.nepochs + 1):\n",
    "        sim_ids_to_train = np.sort(rng.choice(sim_ids_all, args.nsims_per_batch, replace=False))\n",
    "        y0_data, tt_data, ytt_data = get_data_for_sim(sim_ids_to_train[0], device=device)\n",
    "        \n",
    "        best_loss = 1e20\n",
    "        for itr in range(1, args.niters + 1):\n",
    "            optimizer.zero_grad()\n",
    "            update_learning_rate(optimizer, decay_rate = 0.999, lowest = args.lr/10)\n",
    "            \n",
    "            pred_y = torch.squeeze(pnode_conv(tt_data, y0_data))\n",
    "            losses = torch.mean(torch.abs(pred_y - ytt_data[:, :input_dim]))\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                val_loss = 0\n",
    "                for i in range(len(sd_calib)):\n",
    "                    y0_data, tt_data, ytt_data = get_data_for_sim(orig_sd_calib_idx[i], device=device)\n",
    "                    val_pred_y = torch.squeeze(pnode_conv(tt_data, y0_data))\n",
    "                    val_loss += torch.mean(torch.abs(val_pred_y - ytt_data[:, :input_dim]))\n",
    "                \n",
    "                message = \"Epoch {:02d}|Iteration {:03d}|Val Losses Agg {:.4f}|Sim {:03d}|Train loss batch {:.4f}|\".format(\n",
    "                        ep,\n",
    "                        itr, \n",
    "                        val_loss,\n",
    "                        sim_ids_to_train[0],\n",
    "                        losses.item())\n",
    "                \n",
    "                logger.info(message)\n",
    "                \n",
    "        if itr % ckpt_freq == 0:\n",
    "            print('saving check point...')\n",
    "            torch.save({'args': args,\n",
    "                        'state_dict': pnode_conv.state_dict(),\n",
    "                       }, ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f12c80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
